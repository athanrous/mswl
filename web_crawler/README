This is README file. My name is Rousinopoulos Athanasios-Ilias.
In this repo i store all my MSWL project's.
More info about , e-mail at athanrous@gmail.com.
Madrid.

The program web crawler ,is a kind of web crawler written in Python.

In order to use correctly the programm , you can dowload the source code available in this repository
and then open a terminal by just typing this :

python mycraaawler.py -n --number-of-levels url


Note : So as to run the application successfully you need to be connected to the internet.

The application receives the following parameters:

Numbers of levels: This parameter is optional and it tells the application how deep it will go. By default the value of this parameter is “1” and to specify a different value it should be done in any of the following ways:
-n {number}, example: -n 3
--number-of-levels {number}, example: --number-of-levels 4
url: This parameter is mandatory and it tells the application the web page that must be read. This parameter must be preceded by “http://” if not the program will not show any result. For example: http://www.example.com


© 2011 GitHub Inc. All rights reserved.
Dedicated Server Powered by the Dedicated Servers and
Cloud Computing of Rackspace Hosting®
